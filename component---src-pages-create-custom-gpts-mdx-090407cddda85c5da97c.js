"use strict";(self.webpackChunklearning_architect_blog=self.webpackChunklearning_architect_blog||[]).push([[824],{2482:function(n,e,t){t.r(e);var a=t(8453),s=t(6540);function o(n){const e=Object.assign({h1:"h1",p:"p",h2:"h2",ol:"ol",li:"li",span:"span",strong:"strong",a:"a"},(0,a.RP)(),n.components);return s.createElement(s.Fragment,null,s.createElement(e.h1,null,"How to create your own GPTs assistant"),"\n","\n",s.createElement(e.p,null,"If you missed OpenAI's Dev Days presentation, you missed out on Sam Altman, the CEO, ~~killed many startups~~ has shown updates to OpenAI and ChatGPT."),"\n",s.createElement(e.p,null,"Haven't seen it? Do yourself a favor and ",s.createElement("a",{href:"https://www.youtube.com/watch?v=U9mJuUkhUzk",target:"_blank"},"watch it here"),". It's not just a presentation; it's a glimpse into the future, at least until the next big thing rolls around."),"\n",s.createElement(e.p,null,"Post-presentation, like many others, I had a lightbulb moment. Why not feed all our internal organization docs to a GPT and let it do the heavy lifting? Then just kick back, relax, and sip coconuts on an island somewhere."),"\n",s.createElement(e.p,null,"Turns out, it's not as easy as Sam made it look. If your company's processes and org structure resemble a labyrinth, you'll need to roll up your sleeves. It's not all AI magic and coconut sipping, unfortunately. But at the same time, it is much-much-much-.....-much easier than it was before. We just need a little bit of wizarding around crafting precise instructions to GPT."),"\n",s.createElement(e.p,null,"As of writing this, internet does not have a lot of takes on how to make it work. So, I decided to put my two cents in and draft one."),"\n","\n",s.createElement(e.h2,null,"First of all - what is custom GPTs?"),"\n",s.createElement(e.p,null,"Imagine ChatGPT but with a personal twist. OpenAI's new brainchild, custom GPTs, let you mold ChatGPT to do, well, pretty much anything. Need to be a trivia champion or a math tutor for the kids? Custom GPTs have got your back. And no, you don’t need a PhD in computer science to create one – it’s as easy as having a chat."),"\n",s.createElement(e.p,null,"The GPT Store, coming soon, is like a playground for these custom GPTs. Share your creation, and who knows, it might just be the next thing everyone's talking about. Worried about privacy? Relax, OpenAI’s got it locked down."),"\n",s.createElement(e.p,null,"As for the future? It's looking like custom GPTs will be doing more real-world tasks. Think of them as your all-knowing digital sidekicks, ready to connect to the world with some API magic."),"\n",s.createElement(e.p,null,"You read more about in ",s.createElement("a",{href:"https://openai.com/blog/introducing-gpts",target:"_blank"},"official release notes on the openai.com"),"."),"\n",s.createElement(e.p,null,"In the summary, it is the same Chat-GPT but with predefined prompt and with ability to use your own dataset. Which a lot..."),"\n",s.createElement(e.h2,null,"How to create your own GPTs assistant"),"\n",s.createElement(e.p,null,"Creating your own GPT assistant is surprisingly simple, almost too easy. First, you'll need a paid subscription to OpenAI. Once you've done that (and trust me, it's worth every penny), head over to the ",s.createElement("a",{href:"https://chat.openai.com/create",target:"_blank"},"GPTs creation wizard"),". Here, you'll essentially be chatting with ChatGPT to create another, more customized ChatGPT."),"\n",s.createElement(e.p,null,'The process is pretty slick. It will ask about purpose of this GPT and then suggest an icon using DALL-E 3 model for your new GPT buddy. Then, through a series of questions and answers, it crafts a unique prompt for your custom GPT. If you switch to tab "Configure" you will see that generated prompt.'),"\n",s.createElement(e.p,null,"Next up: uploading your dataset. Ideally, this should be plain or simply formatted text, like Markdown. But hey, ChatGPT now gets PDFs, Word documents, and who knows what else. Some folks on social media even claim it can unzip archives and read the text files inside!"),"\n",s.createElement(e.p,null,"For a lot of use-cases, this setup works like magic, no further tweaking needed."),"\n",s.createElement(e.p,null,"But, there are a couple of hiccups you might run into:"),"\n",s.createElement(e.ol,null,"\n",s.createElement(e.li,null,"Your dataset might not be exactly GPT-friendly."),"\n",s.createElement(e.li,null,"It might lack comprehensive answers, which gets tricky if your organization has complex processes. Fine-tuning custom GPTs isn't just a chat away in these cases."),"\n"),"\n",s.createElement(e.p,null,"Let's dive deeper into these issues and explore how to tackle them."),"\n",s.createElement(e.h2,null,"How to make your dataset GPT-friendly"),"\n",s.createElement(e.p,null,"GPTs are trained on a lot of data, and they're pretty good at figuring out what's what. But, they're not perfect. If your dataset is a mess, you'll need to clean it up before feeding it to GPT."),"\n",s.createElement(e.p,null,"Picture this: I'm knee-deep in a digital desert of documents. I've got a wild bunch of PDF files, a scattering of Markdown files, a few stray Word documents caught in the wind, and a wiki, like a mirage, hosted on-premise. It's a mixed-up, muddled-up, shook-up world of data, and I'm diving in, headfirst."),"\n",s.createElement(e.span,{dangerouslySetInnerHTML:{__html:'<span\n      class="gatsby-resp-image-wrapper"\n      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1024px; "\n    >\n      <a\n    class="gatsby-resp-image-link"\n    href="/static/98f0d29795733db0c6d1abdd8218093a/2bef9/dall-e-gen-las-vegas-illustration.png"\n    style="display: block"\n    target="_blank"\n    rel="noopener"\n  >\n    <span\n    class="gatsby-resp-image-background-image"\n    style="padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(\'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFg0lEQVR42g2Ua1DThwHA/+vu1l53tw/rnb2t88t69XZtvc521+t6Y513667K1tatdifVOQRBxkApUkAgRm88IshLMAnlERAa5BUgGiIgTXiKBuQhhFcIz0DeECDERPsbH373+/j79hNOKT0EFXl5M9PD0bxVfhKi50cJbvanbPLWVTcvJXrZl7LFayIP+y+5eDHZx74EJ2+kWHgnZ5cD6V5eFvk5nG3nQOomwu/kDl6QexB3WpmesZAta+OXBSsc+tZBg26GHxds8KsbVspU06Q0ziFkuvmTfJHt/jbiNKsIedscLZjCbbKRpV1CeKVqg+DCEdbNTpZs27TPOvlto5VXlJv8otrOSxUOXpSaOVg+xwGlnZerN/lGawbjQ/5eN8cLsiVezx/njMLIexoPQtlSgPclesIvqhh7ZOKg3kWobo0GgxlB6UBUPkO8do6fa3d5s9nJq3dc/FrtJPh7F/vDFZyIlvJTvQ/hzg7Z5mcIJv8PaAJwvNlE2M0uTi4+5/jAOuEPLPzs/g5n6sz83rDDG91ejna5qG59wiGdg1d7NtlXNspbolaO61dpnHVgtNgRFMVTGHr7KfUHSF8JUG7e5tyTDc4ptZTeK+a1URenOpc5tuTjhHad3B47b09v8bd7g3wwH+Dt2V0yah4xOrnO+LIDoSConVVxLP26dK487iHECdnX6uGTKIh8lyhlISG3xugxGPnQ8ZQ/r3mJm17myFaAm1MWbtieIl7wIVl/RqHJjSA7IseUkA7XT/C8JpQcr4XQVQ8FF4sRy1WULtv5Zq/81dQyyXY3iqU1Ej0eZE4/2jEbDVs+xH4nxZoB9JE3ELpCczAn5OO7eR6kYUx0Z5HlcRHlhytPA+TtBJA8h9w1GyL3BsNdC9RMr3HR4iJs24u0bgLb+QwMn1XQ814awlC5gl1JFRMSGaX5GqzFV1i8n0/9/Cy3javUPZ7j6o6fonUHkt0dUtc2EblcSGec9JcOoIvoRZv2CFW4jqbjEoR5tR5Nwf8YqS3DpG1jorMNf0cpgZYsvNpGRkZH0DrXaPJtU7O5Q4N1B0O7lb6KRYxZjzHlD7JUrmNR0YSssg1B3z1BaOZJWnQKJkcWMQwZMS2sMDs9i2lqnImxPc/NY3ZamHLb9gJ79FmYMCwyOmJicnyWgaGHfKetZPDRLMJn8TG8E/UborKTqVQNUdXajUo9QqZMR+OdATru99H1YAir9QEOu55JYydZ9VOUNnRRqsqlUtmJovEJcUUZpEilCJ9ExXAk+hB3C2+g+fYauRV6OioUXDgdTU1uMiZ9Ee6VWrYc9disKrZXazH2V2G+n0fZ1UiSv05nsiiF66KLxMUEIURGpHHuyj/xl0SSl5ZFWO4EiVUO7qkacLf/G11rJdVNlbRrilFXZeK1q3BbK3i2LGW4NpZjZ7KpEIsxF8YynBOBIE8I5dalj1DGXUBVWUJOhoyopDp6O+vxG2LRV13mvFhOWWYaslNfYBtPp1FawuDIEiZNAV1ff0nL5dOIE+U0V3cj9PfN0yutRhScieRf12mLT2RefowVbQy+sf/iGk5l6HsJfzh4jKKYaMZKztAe/g/u3a5ktL2Y+bpYzNkniQ2+QGiqGqHwu0VutVm4W9XAYG4Yz2oPM6++RFffCqPDj5m/k8pASRzlGZF0VySScfg0TV98yNjd/zDU18zIkgOLdYHLhWqC4nsQQnJN3Ewp5uHZD1hLeh9KPsIoj9nb1hxtzWroPcGGUYxn4ToNymambyex0RfDjDKMZlESLdnl1DY/4Wy6nj9GqBA+vTxI319P0v3pXxj96nPyI4roSI7HJvqS9bwQaAlGLSvB1JLKcOM1fO2xbHacZVMfzQ+tn/Pg4yBihFA+fj2J4NAm/g9W06FRsochIQAAAABJRU5ErkJggg==\'); background-size: cover; display: block;"\n  ></span>\n  <img\n        class="gatsby-resp-image-image"\n        alt="Fear and Loathing in Las Vegas"\n        title=""\n        src="/static/98f0d29795733db0c6d1abdd8218093a/2bef9/dall-e-gen-las-vegas-illustration.png"\n        srcset="/static/98f0d29795733db0c6d1abdd8218093a/5a46d/dall-e-gen-las-vegas-illustration.png 300w,\n/static/98f0d29795733db0c6d1abdd8218093a/0a47e/dall-e-gen-las-vegas-illustration.png 600w,\n/static/98f0d29795733db0c6d1abdd8218093a/2bef9/dall-e-gen-las-vegas-illustration.png 1024w"\n        sizes="(max-width: 1024px) 100vw, 1024px"\n        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"\n        loading="lazy"\n        decoding="async"\n      />\n  </a>\n    </span>'}}),"\n",s.createElement(e.p,null,"When I first experimented with creating a custom GPT, I fed it raw documents exported from our internal wiki, including some PDFs of notably poor quality. Initially, I didn't realize the impact this would have. The responses from the GPT were often unsatisfactory, and I mistakenly thought the fault lay with ChatGPT's capabilities. However, a deeper dive into preprocessing the knowledge base was revealing."),"\n",s.createElement(e.p,null,"I used ChatGPT to help with generating JavaScript code to extract text from the PDFs. The output was bizarre and hard to understand, which made it clear: if this was what the AI was processing, it probably couldn't make much sense of it either. The problem wasn't with ChatGPT’s intelligence, but with the quality of the data I was providing."),"\n",s.createElement(e.p,null,"I developed the following workflow to effectively preprocess our knowledge base:"),"\n",s.createElement(e.ol,null,"\n",s.createElement(e.li,null,s.createElement(e.strong,null,"Export Wiki Pages"),": Initially, I exported pages from our wiki into DOC format."),"\n",s.createElement(e.li,null,s.createElement(e.strong,null,"Format Conversion"),": Since DOC files aren't parser-friendly, I converted them to the more manageable DOCX format."),"\n",s.createElement(e.li,null,s.createElement(e.strong,null,"Extracting Text"),": The next step involved transforming the DOCX files into a lighter format. I opted to extract plain text from these documents."),"\n",s.createElement(e.li,null,s.createElement(e.strong,null,"Content Enhancement"),": To refine the content further, I utilized the OpenAI API. This involved crafting a specific prompt for the ChatGPT API, enabling it to process and structure the text input for better indexing and clarity."),"\n"),"\n",s.createElement(e.p,null,"Below is a simplified version of the script that I used for this process."),"\n",s.createElement(e.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="js"><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> mammoth <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">\'mammoth\'</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// package for working with .docx files</span>\r\n<span class="token keyword">const</span> OpenAi <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">\'openai\'</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// openai official client for JS/TS</span>\r\n<span class="token keyword">const</span> fs <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">\'fs\'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n\r\n<span class="token keyword">function</span> <span class="token function">extractTextFromDocx</span><span class="token punctuation">(</span><span class="token parameter">filePath</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>\r\n    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Promise</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token parameter">resolve<span class="token punctuation">,</span> reject</span><span class="token punctuation">)</span> <span class="token operator">=></span> <span class="token punctuation">{</span>\r\n        mammoth<span class="token punctuation">.</span><span class="token function">extractRawText</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token literal-property property">path</span><span class="token operator">:</span> filePath<span class="token punctuation">}</span><span class="token punctuation">)</span>\r\n            <span class="token punctuation">.</span><span class="token function">then</span><span class="token punctuation">(</span><span class="token parameter">result</span> <span class="token operator">=></span> <span class="token function">resolve</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>value<span class="token punctuation">)</span><span class="token punctuation">)</span>\r\n            <span class="token punctuation">.</span><span class="token function">catch</span><span class="token punctuation">(</span><span class="token parameter">err</span> <span class="token operator">=></span> <span class="token function">reject</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n<span class="token punctuation">}</span>\r\n\r\n<span class="token keyword">const</span> prompt <span class="token operator">=</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">\r\nConvert the html in the next message into a structured markdown document suitable for indexing by a Large Language Model.\r\nDo not explain anything and return the document as is.\r\nTo categorize projects, consider using generalized terms for technologies or platforms.\r\n\r\nFor every valuable piece of document generate a markdown record in the response as follows:\r\n### [The heading of the statement]\r\n\r\n**Project**: [Identify the project based on content or specify \'Unknown\']\r\n\r\n**Type**: [Classify the document as \'troubleshooting\', \'guidance\', or \'explanation\']\r\n\r\n**Description**: [Rewrite the content in a meaningful and concise way, maintaining as much of the original text as possible for LLM to use in responding to queries]</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">;</span>\r\n\r\n<span class="token keyword">class</span> <span class="token class-name">OpenAiMarkdownTransformer</span> <span class="token punctuation">{</span>\r\n    <span class="token function">constructor</span><span class="token punctuation">(</span><span class="token parameter">apiKey</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>\r\n        <span class="token keyword">this</span><span class="token punctuation">.</span>openai <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">OpenAi</span><span class="token punctuation">(</span><span class="token punctuation">{</span> apiKey <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n    <span class="token punctuation">}</span>\r\n\r\n    <span class="token keyword">async</span> <span class="token function">transformToMarkdown</span><span class="token punctuation">(</span><span class="token parameter">text</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>\r\n        console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token string">\'Sending text to OpenAI:\'</span><span class="token punctuation">,</span> text<span class="token punctuation">.</span>length<span class="token punctuation">,</span> <span class="token string">\'characters\'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n        <span class="token keyword">const</span> response <span class="token operator">=</span> <span class="token keyword">await</span> <span class="token keyword">this</span><span class="token punctuation">.</span>openai<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">{</span>\r\n            <span class="token literal-property property">model</span><span class="token operator">:</span> <span class="token string">\'gpt-4-1106-preview\'</span><span class="token punctuation">,</span> <span class="token comment">// this is just announced turbo model, you can try other available</span>\r\n            <span class="token literal-property property">messages</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{</span> <span class="token literal-property property">role</span><span class="token operator">:</span> <span class="token string">\'user\'</span><span class="token punctuation">,</span> <span class="token literal-property property">content</span><span class="token operator">:</span> prompt <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span> <span class="token literal-property property">role</span><span class="token operator">:</span> <span class="token string">\'user\'</span><span class="token punctuation">,</span> <span class="token literal-property property">content</span><span class="token operator">:</span> text <span class="token punctuation">}</span><span class="token punctuation">]</span>\r\n        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n        <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token parameter">choice</span> <span class="token operator">=></span> choice<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">.</span><span class="token function">trim</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token string">\'\\n\'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n    <span class="token punctuation">}</span>\r\n<span class="token punctuation">}</span>\r\n\r\n<span class="token keyword">async</span> <span class="token keyword">function</span> <span class="token function">processDocument</span><span class="token punctuation">(</span><span class="token parameter">filePath</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>\r\n    <span class="token keyword">const</span> apiKey <span class="token operator">=</span> process<span class="token punctuation">.</span>env<span class="token punctuation">.</span><span class="token constant">OPEN_AI_API_KEY</span><span class="token punctuation">;</span>\r\n    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>apiKey<span class="token punctuation">)</span> <span class="token punctuation">{</span>\r\n        console<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span><span class="token string">\'Missing API key\'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n        process<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n    <span class="token punctuation">}</span>\r\n\r\n    <span class="token keyword">const</span> transformer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">OpenAiMarkdownTransformer</span><span class="token punctuation">(</span>apiKey<span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n\t<span class="token comment">// text might be bigger than context window (8k tokens for now, while Chat-GPT turbo with 128k tokens context is not available for everyone)</span>\r\n\t<span class="token comment">// so you might need to split it before sending to OpenAI</span>\r\n    <span class="token keyword">const</span> text <span class="token operator">=</span> <span class="token keyword">await</span> <span class="token function">extractTextFromDocx</span><span class="token punctuation">(</span>filePath<span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n    <span class="token keyword">const</span> markdown <span class="token operator">=</span> <span class="token keyword">await</span> transformer<span class="token punctuation">.</span><span class="token function">transformToMarkdown</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n    fs<span class="token punctuation">.</span><span class="token function">writeFileSync</span><span class="token punctuation">(</span><span class="token string">\'./output.md\'</span><span class="token punctuation">,</span> markdown<span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n    console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token string">\'Markdown file created\'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>\r\n<span class="token punctuation">}</span>\r\n\r\n<span class="token comment">// Replace the file path with your document\'s path</span>\r\n<span class="token function">processDocument</span><span class="token punctuation">(</span><span class="token string">\'./path/to/your/document.docx\'</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>'}}),"\n",s.createElement(e.p,null,"This script was instrumental in transforming our proprietary wiki format into a readable and concise knowledge base. While a few Markdown files needed manual tweaking, it was significantly easier than sorting out the initial disarray."),"\n",s.createElement(e.p,null,"Regarding images in our existing wiki: not all are essential for the knowledge base. However, some key decision trees proved valuable. By leveraging ChatGPT, I could convert these image-based trees into text formats, like ",s.createElement("a",{href:"https://mermaid.live/edit",target:"_blank"},"mermaid syntax")," or even plain text."),"\n",s.createElement(e.p,null,"Now, we've got a solid knowledge base. But what if it only covers a fraction of our processes? We need to tailor our assistant to specific needs. The initial prompt isn't very rigid or formal, so let's explore how we can refine and proceed with it."),"\n",s.createElement(e.h2,null,"How to refine your prompt"),"\n",s.createElement(e.p,null,"The prompts auto-generated by leveraging GPT can often be quite broad and non-specific."),"\n",s.createElement(e.p,null,"Take, for instance, this prompt crafted for an internal platform team's GPT:"),"\n",s.createElement(e.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">As SysBase Assistant, my primary role is to provide first-level assistance to platform teams working on system bases for other technical product teams.\r\n\r\nI\'ll focus on offering guidance, troubleshooting tips, and best practices related to system architecture, configurations, and optimizations.\r\n\r\nI will avoid providing advice outside my expertise, like detailed coding solutions or hardware-specific recommendations\r\n\r\nWhen faced with ambiguous queries, I\'ll ask for clarification to ensure accurate and helpful responses.\r\n\r\nMy interactions will be professional, informative, and tailored to the technical level of the user.</code></pre></div>'}}),"\n",s.createElement(e.p,null,"This example highlights the typical nature of these prompts. They're general, but there's room for refinement to make them more precise and applicable to specific use cases."),"\n",s.createElement(e.p,null,"What I really needed was a specific process for the GPT to follow, one that minimizes its imaginative leaps about non-existent staff or irrelevant company details."),"\n",s.createElement(e.p,null,"In such scenarios, the usual user-friendly approach of casually tailoring prompts through chatting with GPT may fall short. This is where the advantages of a human, biologically-based brain come into play. We need the nuanced understanding and contextual awareness that only a human can provide to refine these prompts effectively."),"\n",s.createElement(e.p,null,"Now a guide from OpenAI team, to build a good instructions to Chat-GPT comes in handy. I really-really recommend to read this guide ",s.createElement("a",{href:"https://platform.openai.com/docs/guides/prompt-engineering",target:"_blank"},"on prompt engineering"),"."),"\n",s.createElement(e.p,null,"In pursuit of a more efficient assistant, my goal was clear: to create a tool that not only precisely uses and leverages the provided knowledgebase but also clearly communicates its limitations to the users. The assistant should explicitly inform users when their queries extend beyond the scope of the knowledgebase, offering suggestions based on its general knowledge as an alternative. If all else fails, it should be capable of generating a relevant search query for the internal wiki, or even a draft ticket for the internal ticketing system, providing a seamless bridge to further assistance."),"\n",s.createElement(e.p,null,"I eventually crafted a solution that embodied these principles, which looks like this"),"\n",s.createElement(e.span,{dangerouslySetInnerHTML:{__html:'<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Platform Assistant is tailored to assist with cloud services, continuous integration, and general system operations issues, focusing on a particular team within a large tech organization.\r\n\r\nIt relies on internal documentation as its primary knowledge base, gathering error messages, troubleshooting steps, and issue details.\r\n\r\nResponses should be action-oriented and concise.\r\n\r\nInstructions:\r\n1. Platform Assistant must search the internal knowledge base before offering general knowledge answers. If information exists there, it should use that precise formulation. Otherwise, it should ask the user before providing general knowledge answers.\r\n2. It should seek details that help locate issues in the knowledge base, understanding specific project contexts and error forms. Example: if a user reports a specific error, the assistant will first ask about the service generating the error.\r\n3. The assistant should not assume organizational structures or tools not mentioned in the documentation. For queries outside its scope, it redirects users as outlined in a responsibilities document.\r\n4. As many development teams lack deep knowledge, the assistant should provide specific, step-by-step instructions rather than vague advice.\r\n5. In addition to the answer, the assistant generates a link to an internal collaboration tool\'s search function with a custom query. Use URL https://wiki.yourorg.com/search?q=&amp;lt;Generated Search Tearm by assisant&amp;gt; to search the internal wiki, for example https://wiki.yourorg.com/search?q=how+to+do+work+effectively+if+I+need+to+create+tickets .\r\n6. If the internal search is unhelpful, the assistant generates a task for the system operations team on an issue tracking platform, following a defined template, including a section for system improvement suggestions.\r\n\r\nGeneral information about the teams that reach assistant:\r\n- Comprises product and system-specific teams.\r\n- Works on different projects. The assistant distinguishes between these projects: project1, project2, ...\r\n- Utilizes specific tools for version control (github), continuous integration (github), and deployment (github ..).\r\n- Services are primarily deployed to a cloud service and container orchestration platforms.\r\n- Team members have limited permissions, restricting resource access.\r\n\r\nTask Template:\r\n\tGeneral Description: &amp;lt;user-provided information&amp;gt;\r\n\tSummary of the conversation: &amp;lt;chat summary&amp;gt;\r\n\tProject: &amp;lt;to be determined by the assistant&amp;gt;\r\n\tSpecific logs or exact errors: &amp;lt;URL_to_exception_log&amp;gt;\r\n\tService name: &amp;lt;affected service&amp;gt;</code></pre></div>'}}),"\n",s.createElement(e.p,null,"This custom GPT assistant, powered by the meticulously prepared knowledge base, stands as a robust tool poised to ease the support workload on our team."),"\n",s.createElement(e.p,null,"Interestingly, during its initial run, I (or rather, the AI through me) managed to resolve an issue while testing the prompt and knowledge base. Despite encountering a few rate limits, the experience was surprisingly enjoyable."),"\n",s.createElement(e.p,null,"Ultimately, I've consolidated all the scripts, the knowledge base, and the prompt into a GIT repository within our organization. This move sets the stage for collaborative enhancement, allowing us to expand the knowledge base and continuously refine our digital helper."),"\n",s.createElement(e.h2,null,"Keeping the Knowledgebase Up-to-Date"),"\n",s.createElement(e.p,null,"As of now, OpenAI doesn't seem to offer an API for updating a custom GPT's knowledgebase directly. Here's my plan for a semi-manual updating process:"),"\n",s.createElement(e.ol,null,"\n",s.createElement(e.li,null,s.createElement(e.strong,null,"Version-Controlled Repository"),": A Git repository for all scripts, documentation exports, and post-processing."),"\n",s.createElement(e.li,null,s.createElement(e.strong,null,"Automated Bundling"),": Using CI tools, automatically create and version a knowledgebase bundle, then store it in an artifacts repository."),"\n",s.createElement(e.li,null,s.createElement(e.strong,null,"Update Notifications"),": Implement a system to notify when a new version of the refined data is available."),"\n",s.createElement(e.li,null,s.createElement(e.strong,null,"Manual Updating"),": Unfortunately manually update the GPT with the new knowledgebase bundle as needed."),"\n"),"\n",s.createElement(e.p,null,"I'm hopeful OpenAI will introduce an API for seamless knowledgebase updates in the future, enabling full automation."),"\n",s.createElement(e.h2,null,"Looking further"),"\n",s.createElement(e.p,null,"Next, I'm looking to further refine and automate the AI experience. Here's what I'm considering:"),"\n",s.createElement(e.ol,null,"\n",s.createElement(e.li,null,"\n",s.createElement(e.p,null,s.createElement(e.strong,null,"API Integration"),": The custom ChatGPT can actually handle API calls. This means integrating an OpenAPI schema (not OpenAI – easy mix-up) to enable real-time API interactions. Imagine it automatically creating tickets and notifying teams."),"\n"),"\n",s.createElement(e.li,null,"\n",s.createElement(e.p,null,s.createElement(e.strong,null,"Enhanced Customization"),": These GPTs use OpenAI's latest ",s.createElement(e.a,{href:"https://platform.openai.com/docs/assistants/overview"},"Assistant API"),", as introduced at the start of this article. OpenAI also released a ",s.createElement(e.a,{href:"https://platform.openai.com/playground?mode=assistant"},"playground")," for the API, which offers a richer interface for debugging inputs and outputs."),"\n"),"\n"),"\n",s.createElement(e.p,null,"I hope someone finds this guide helpful and is excited to see where this technology can take us."))}e.default=function(n){void 0===n&&(n={});const{wrapper:e}=Object.assign({},(0,a.RP)(),n.components);return e?s.createElement(e,n,s.createElement(o,n)):o(n)}},8453:function(n,e,t){t.d(e,{RP:function(){return o}});var a=t(6540);const s=a.createContext({});function o(n){const e=a.useContext(s);return a.useMemo(()=>"function"==typeof n?n(e):{...e,...n},[e,n])}}}]);
//# sourceMappingURL=component---src-pages-create-custom-gpts-mdx-090407cddda85c5da97c.js.map